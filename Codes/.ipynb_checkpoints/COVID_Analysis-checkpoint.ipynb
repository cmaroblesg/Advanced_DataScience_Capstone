{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID 19 Mexican Analysis\n",
    "## Cesar Robles\n",
    "### What is COVID-19?\n",
    "\n",
    "**COVID-19** is the infectious disease caused by the coronavirus, *SARS-CoV-2*, which is a respiratory pathogen. WHO (World Health Organization) first learned of this new virus from cases in Wuhan, People’s Republic of China on 31 December 2019.\n",
    "\n",
    "The most common symptoms of COVID-19 are:\n",
    "* Fever\n",
    "* Dry cough\n",
    "* Fatigue\n",
    "\n",
    "Other symptoms that are less common and may affect some patients include:\n",
    "* Loss of taste or smell,\n",
    "* Nasal congestion,\n",
    "* Conjunctivitis (also known as red eyes)\n",
    "* Sore throat,\n",
    "* Headache,\n",
    "* Muscle or joint pain,\n",
    "* Different types of skin rash,\n",
    "* Nausea or vomiting,\n",
    "* Diarrhea,\n",
    "* Chills or dizziness.\n",
    "\n",
    "Symptoms are usually mild. Some people become infected but only have very mild symptoms or none at all.\n",
    "\n",
    "Symptoms of severe COVID‐19 disease include:\n",
    "* Shortness of breath,\n",
    "* Loss of appetite,\n",
    "* Confusion,\n",
    "* Persistent pain or pressure in the chest,\n",
    "* High temperature (above 38 °C).\n",
    "\n",
    "Other less common symptoms are:\n",
    "* Irritability,\n",
    "* Confusion,\n",
    "* Reduced consciousness (sometimes associated with seizures),\n",
    "* Anxiety,\n",
    "* Depression,\n",
    "* Sleep disorders,\n",
    "* More severe and rare neurological complications such as strokes, brain inflammation, delirium and nerve damage.\n",
    "\n",
    "People of all ages who experience fever and/or cough associated with difficulty breathing or shortness of breath, chest pain or pressure, or loss of speech or movement should seek medical care immediately. If possible, call your health care provider, hotline or health facility first, so you can be directed to the right clinic.\n",
    "\n",
    "[https://www.who.int/emergencies/diseases/novel-coronavirus-2019/question-and-answers-hub/q-a-detail/q-a-coronaviruses#:~:text=symptoms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVID-19 in Mexico\n",
    "\n",
    "The virus was confirmed to have reached Mexico in February 2020. However, the National Council of Science and Technology (CONACYT) reported two cases of COVID-19 in mid-January 2020 in the states of Nayarit and Tabasco, one case per state. As of October, there had been near 800,000 confirmed cases of COVID-19 in Mexico and circa 88,000 reported deaths, although the Secretariat of Health, through the \"Programa Centinela\" (Spanish for \"Sentinel Program\") estimated in mid July 2020 that there were more than 2,875,734 cases in Mexico, because they were considering the total number of cases confirmed as a statistical sample.\n",
    "\n",
    "[https://en.wikipedia.org/wiki/COVID-19_pandemic_in_Mexico]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Needed libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from requests import request\n",
    "import urllib.request\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import folium \n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# colour pallette\n",
    "cnf, dth, rec, act = '#f7d619', '#d43d56', '#48cf46', '#6b9be8' \n",
    "\n",
    "# Use to hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import Markdown\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the necesary files are stored in Files directory. The following code extract the information from a zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('unzip ../Files/db.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Files/mex_covid_daily.csv',engine='python')\n",
    "print('Confirmed cases: {0:,.0f}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting columns to datetime**\n",
    "\n",
    "Converting all the columns that have dates. There are 3 date columns (FECHA_INGRESO, FECHA_SINTOMAS and FECHA_DEF) the only column with problems is FECHA_DEF due to the strange date ('9999-99-99').\n",
    "* FECHA_INGRESO is the date when the person goes to the hospital.\n",
    "* FECHA_SINTOMAS is the date when the person has the COVID Symptoms.\n",
    "* FECHA_DEF is the date when the infected person dies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['FECHA_ACTUALIZACION'] = pd.to_datetime(data['FECHA_ACTUALIZACION'])\n",
    "data['FECHA_INGRESO'] = pd.to_datetime(data['FECHA_INGRESO'])\n",
    "data['FECHA_SINTOMAS'] = pd.to_datetime(data['FECHA_SINTOMAS'])\n",
    "data.loc[(data['FECHA_DEF'].isin(['9999-99-99'])),'FECHA_DEF'] = ''\n",
    "data.loc[(data['FECHA_DEF'].isnull()),'FECHA_DEF']='0'\n",
    "data['FECHA_DEF']=pd.to_datetime(data['FECHA_DEF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of deceased people in Mexico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dead people: {0:,.0f}'.format(data.loc[(data['Status'].isin(['Dead'])),'ID_REGISTRO'].count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the more useful columns from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['ID_REGISTRO','FECHA_INGRESO','FECHA_DEF',\n",
    " 'SECTOR_DESC','SEXO_DESC','TIPO_PACIENTE_DESC','ENTIDAD_FEDERATIVA_RES',\n",
    " 'ABREVIATURA_RES','INTUBADO_DESC', 'NEUMONIA_DESC','DIABETES_DESC','EPOC_DESC',\n",
    " 'ASMA_DESC','INMUSUPR_DESC','OTRA_COM_DESC','CARDIOVASCULAR_DESC','OBESIDAD_DESC',\n",
    " 'RENAL_CRONICA_DESC','TABAQUISMO_DESC','OTRO_CASO_DESC',\n",
    " 'HIPERTENSION_DESC','MUNICIPIO_RES_DESC',\n",
    " 'EDAD_CLASS','Status']]\n",
    "print('Total confirmed  people: {0:,.0f}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the final numbers of infected, active and alive people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['Status'],as_index=False)['ID_REGISTRO'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the confirmed cases by states. In Mexico, we have 32 registered states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirm = data.groupby(['ENTIDAD_FEDERATIVA_RES'],as_index=False)['ID_REGISTRO'].count()\n",
    "confirm = confirm.rename(columns={'ID_REGISTRO':'Confirmed'})\n",
    "confirm['Confirmed'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the total deceased people by States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muertos = data.loc[(data['Status'].isin(['Dead']))]\n",
    "deceased = muertos.groupby(['ENTIDAD_FEDERATIVA_RES'],as_index=False)['ID_REGISTRO'].count()\n",
    "deceased = deceased.rename(columns={'ID_REGISTRO':'Deceased'})\n",
    "deceased.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of recovered people by States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recuperados = data.loc[(data['Status'].isin(['Alive']))]\n",
    "recovered = recuperados.groupby(['ENTIDAD_FEDERATIVA_RES'],as_index=False)['ID_REGISTRO'].count()\n",
    "recovered = recovered.rename(columns={'ID_REGISTRO':'Recovered'})\n",
    "recovered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the total active people by states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activos = data.loc[(data['Status'].isin(['Active']))]\n",
    "active = activos.groupby(['ENTIDAD_FEDERATIVA_RES'],as_index=False)['ID_REGISTRO'].count()\n",
    "active = active.rename(columns={'ID_REGISTRO':'Active'})\n",
    "active.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all the data into a simple table to be used further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData=pd.merge(confirm,deceased)\n",
    "newData=pd.merge(newData,recovered)\n",
    "newData=pd.merge(newData,active)\n",
    "newData.head(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the latitude and length for all the states in Mexico. This information will be used into map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states=[['AGUASCALIENTES',21.87945992,-102.2904135],\n",
    "['BAJA CALIFORNIA',30.76405113,-116.0092603],\n",
    "['BAJA CALIFORNIA SUR',26.01333335,-111.3516635],\n",
    "['CAMPECHE',18.65365928,-91.82448019],\n",
    "['CHIAPAS',16.74999697,-92.63337447],\n",
    "['CHIHUAHUA',26.93335472,-105.6666358],\n",
    "['COAHUILA DE ZARAGOZA',28.32998781,-100.8499789],\n",
    "['COLIMA',18.92038129,-103.8799748],\n",
    "['CIUDAD DE MÉXICO',19.44244244,-99.1309882],\n",
    "['DURANGO',25.57005292,-103.5000238],\n",
    "['GUANAJUATO',20.67001609,-101.4999909],\n",
    "['GUERRERO',17.54997398,-99.5000096],\n",
    "['HIDALGO',20.17043418,-98.73003076],\n",
    "['JALISCO',19.77001935,-104.3699966],\n",
    "['MICHOACÁN DE OCAMPO',19.41001548,-99.02998661],\n",
    "['MORELOS',19.67997316,-100.569996],\n",
    "['MÉXICO',18.92110476,-99.23999964],\n",
    "['NAYARIT',21.81999758,-105.2200481],\n",
    "['NUEVO LEÓN',25.1899986,-99.83998885],\n",
    "['OAXACA',16.42999066,-95.01999882],\n",
    "['PUEBLA',18.90002077,-98.44999618],\n",
    "['QUERÉTARO',20.37998212,-100.0000308],\n",
    "['QUINTANA ROO',21.20839057,-86.7114549],\n",
    "['SAN LUIS POTOSÍ',22.00001243,-99.66999923],\n",
    "['SINALOA',23.19999086,-106.2300381],\n",
    "['SONORA',27.58000775,-109.9299931],\n",
    "['TABASCO',18.40002545,-93.22997888],\n",
    "['TAMAULIPAS',22.73335268,-98.95001734],\n",
    "['TLAXCALA',19.31999514,-98.2300096],\n",
    "['VERACRUZ DE IGNACIO DE LA LLAVE',17.93997601,-94.73999007],\n",
    "['YUCATÁN',21.09998985,-89.27998743],\n",
    "['ZACATECAS',22.35001691,-102.88001]]\n",
    "states=pd.DataFrame(states,columns=['ENTIDAD_FEDERATIVA_RES','Latitude','Longitude'])\n",
    "newData = newData.join(states.set_index('ENTIDAD_FEDERATIVA_RES'),on='ENTIDAD_FEDERATIVA_RES')\n",
    "newData.head(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the Mortality and Recovered rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData['Mortality_Rate']=newData['Deceased']/newData['Confirmed'] * 100\n",
    "newData['Recovery_Rate']=newData['Recovered']/newData['Confirmed'] * 100\n",
    "newData.head(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the table by its confirmed cases by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData=newData.sort_values(by=['Confirmed'],ascending=False)\n",
    "newData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphical analysis for the Recovered, Deceased and Active people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "#  subset columns\n",
    "temp = newData[['Active', 'Deceased', 'Recovered']]\n",
    "temp = temp.iloc[:,:]\n",
    "\n",
    "# rename columns\n",
    "temp.columns = ['Active', 'Deceased', 'Recovered']\n",
    "\n",
    "# melt into longer format\n",
    "tm = temp.melt(value_vars=['Active', 'Deceased', 'Recovered'])\n",
    "\n",
    "# plot\n",
    "fig_1 = px.treemap(tm, path=[\"variable\"], values=\"value\", height=250, color_discrete_sequence=[rec, dth, act], title='Latest stats')\n",
    "fig_1.data[0].textinfo = 'label+text+value'\n",
    "fig_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping phase\n",
    "\n",
    "Extracting the information based on its datetime.\n",
    "\n",
    "**Confirmed cases by date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed=data.groupby(['FECHA_INGRESO'],as_index=False)['ID_REGISTRO'].count()\n",
    "confirmed=confirmed.rename(columns={'ID_REGISTRO':'Confirmed'})\n",
    "confirmed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deceased cases by date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dead = data.loc[(data['Status'].isin(['Dead']))]\n",
    "dead = dead.groupby(['FECHA_INGRESO'],as_index=False)['ID_REGISTRO'].count()\n",
    "dead = dead.rename(columns={'ID_REGISTRO':'Dead'})\n",
    "dead.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recover people by date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recover = data.loc[(data['Status'].isin(['Alive']))]\n",
    "recover = recover.groupby(['FECHA_INGRESO'],as_index=False)['ID_REGISTRO'].count()\n",
    "recover = recover.rename(columns={'ID_REGISTRO':'Recover'})\n",
    "recover.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Active people by date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active = data.loc[(data['Status'].isin(['Active']))]\n",
    "active = active.groupby(['FECHA_INGRESO'],as_index=False)['ID_REGISTRO'].count()\n",
    "active = active.rename(columns={'ID_REGISTRO':'Active'})\n",
    "active.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the daily based to be analysed further**\n",
    "\n",
    "In this part, the confirmed, recover, active and dead people are grouped. This dataframe will be used to forecast the number of confirm people and also the number of deads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = confirmed.join(active.set_index('FECHA_INGRESO'),on='FECHA_INGRESO')\n",
    "daily = daily.join(recover.set_index('FECHA_INGRESO'),on='FECHA_INGRESO')\n",
    "daily = daily.join(dead.set_index('FECHA_INGRESO'),on='FECHA_INGRESO')\n",
    "daily = daily.fillna(0.0)\n",
    "daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the columns to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily['Dead']=daily['Dead'].astype(int)\n",
    "daily['Confirmed']=daily['Confirmed'].astype(int)\n",
    "daily['Recover']=daily['Recover'].astype(int)\n",
    "daily['Active']=daily['Active'].astype(int)\n",
    "daily=daily.rename(columns={'FECHA_INGRESO':'Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the daily base\n",
    "\n",
    "Ploting the information to check the deceased behaviour. The following method use the daily base and group the information by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_daily(col, hue):\n",
    "    fig = px.bar(daily, x=\"Date\", y=col, title=col, \n",
    "                 color_discrete_sequence=[hue])\n",
    "    fig.update_layout(title=col, xaxis_title=\"\", yaxis_title=\"\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmed cases plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_daily('Confirmed','#F9E010')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deceased people graphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_daily('Dead','#E2380A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reccover people cases in a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_daily('Recover','#41E20A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting analysis\n",
    "\n",
    "Facebook phrophet library is used to perform the forecast analysis. This library is selected because it follows the *sklearn* model API. In this sense, an instance of the Prophet class can be created and then call its fit and predict methods.\n",
    "\n",
    "The input to Prophet is always a dataframe with two columns: **ds** and **y**. The ds (datestamp) column should be of a format expected by Pandas, ideally YYYY-MM-DD for a date or YYYY-MM-DD HH:MM:SS for a timestamp. The y column must be numeric, and represents the measurement we wish to forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = daily[['Date','Confirmed']]\n",
    "df.columns = ['ds' , 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing fbprophet\n",
    "from fbprophet import Prophet\n",
    "\n",
    "# model\n",
    "m = Prophet(daily_seasonality=False,yearly_seasonality=False)\n",
    "\n",
    "# fitting the model\n",
    "m.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of periods was chosen to predict the number of confirm cases for the rest of the year. This analysis was perform to analyse the behaviour of the confirm cases and determine how many infected people will be there by state and take the corresponding actions to mitigate this illnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(periods = 70) \n",
    "future.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = m.predict(future)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet.plot import plot_plotly\n",
    "fig = plot_plotly(m, forecast)  # This returns a plotly Figure\n",
    "fig.update_layout(\n",
    "                  autosize=False,\n",
    "                  width= 750,\n",
    "                  height= 800,\n",
    "    title_text='<b>Covid-19 Total cases Forecast<b>',\n",
    "    title_x=0.5,)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graphic illustrates the behaviour of the data. In this sense, the library can model the behaviour of the data. One of the most difficult problems with this graphic is the data. Mexico collects the data every day but unfortunately, the weekends are less accurate that the other days.\n",
    "\n",
    "The Mexican sentinel program are very effective to simulate and calculate the number of infected people. However, dur to the fear to the deceased, many people do not go outside on weekends. Being this the first hipothesis to understand the graphic above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the curve\n",
    "\n",
    "Trying to fit these class of curve is very difficul, because there are not particular method to do that. The easiest way to do that is taking into consideration the predicted output from the phrophet library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import scipy\n",
    "from plotly.offline import iplot\n",
    "\n",
    "def plot_exponential_fit_data(d_df, title, delta, p0):\n",
    "    d_df = d_df.sort_values(by=['Date'], ascending=True)\n",
    "    d_df['x'] = np.arange(len(d_df)) + 1\n",
    "    d_df['y'] = d_df['Confirmed']\n",
    "\n",
    "    x = d_df['x'][:-delta]\n",
    "    y = d_df['y'][:-delta]\n",
    "    y_fit = forecast['yhat']\n",
    "    \n",
    "    traceC = go.Scatter(\n",
    "        x=d_df['x'][:-delta], y=d_df['y'][:-delta],\n",
    "        name=\"Confirmed (included for fit)\",\n",
    "        marker=dict(color=\"Red\"),\n",
    "        mode = \"markers+lines\",\n",
    "        text=d_df['Confirmed'],\n",
    "    )\n",
    "\n",
    "    traceV = go.Scatter(\n",
    "        x=d_df['x'][-delta-1:], y=d_df['y'][-delta-1:],\n",
    "        name=\"Confirmed (validation)\",\n",
    "        marker=dict(color=\"blue\"),\n",
    "        mode = \"markers+lines\",\n",
    "        text=d_df['Confirmed'],\n",
    "    )\n",
    "    \n",
    "    traceP = go.Scatter(\n",
    "        x=np.array(x), y=y_fit,\n",
    "        name=\"Projected values (fit curve)\",\n",
    "        marker=dict(color=\"green\"),\n",
    "        mode = \"lines\",\n",
    "        text=y_fit,\n",
    "    )\n",
    "\n",
    "    data = [traceC, traceV, traceP]\n",
    "\n",
    "    layout = dict(title = 'Confirmed cases and curve projection',\n",
    "          xaxis = dict(title = 'Day since first case', showticklabels=True), \n",
    "          yaxis = dict(title = 'Number of cases'),plot_bgcolor='rgb(275, 270, 273)',\n",
    "          hovermode = 'closest'\n",
    "         )\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    iplot(fig, filename='covid-exponential-forecast')\n",
    "\n",
    "p0 = (40, 0.7)\n",
    "plot_exponential_fit_data(daily, 'I', 15, p0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphic above illustrates the behaviour of the confirmed cases. The green line represents the projected values that are emulating the behaviour due to the data. The red colour is plotting the real confirmed cases andd finally the blue line is plotting the forecasted data. In this case, the behaviour of the curve confirms the Mexican reality on the outbreak. We can confirm everyday the information by watching the news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Forecasting\n",
    "\n",
    "A *time series* is a series of data points indexed (or listed or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data. Time Series analysis can be useful to see how a given asset, security or economic variable changes over time. Examples of time series are heights of ocean tides, counts of sunspots, and the daily closing value of the Dow Jones Industrial Average.\n",
    "\n",
    "Time series are very frequently plotted via run charts (a temporal line chart). Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering, and largely in any domain of applied science and engineering which involves temporal measurements.\n",
    "\n",
    "Time series analysis comprises methods for analyzing time series data in order to extract meaningful statistics and other characteristics of the data. Time series forecasting is the use of a model to predict future values based on previously observed values. While regression analysis is often employed in such a way as to test theories that the current values of one or more independent time series affect the current value of another time series, this type of analysis of time series is not called \"time series analysis\", which focuses on comparing values of a single time series or multiple dependent time series at different points in time. Interrupted time series analysis is the analysis of interventions on a single time series.\n",
    "\n",
    "Time series data have a natural temporal ordering. This makes time series analysis distinct from cross-sectional studies, in which there is no natural ordering of the observations (e.g. explaining people's wages by reference to their respective education levels, where the individuals' data could be entered in any order). Time series analysis is also distinct from spatial data analysis where the observations typically relate to geographical locations (e.g. accounting for house prices by the location as well as the intrinsic characteristics of the houses). A stochastic model for a time series will generally reflect the fact that observations close together in time will be more closely related than observations further apart. In addition, time series models will often make use of the natural one-way ordering of time so that values for a given period will be expressed as deriving in some way from past values, rather than from future values (see time reversibility.)\n",
    "\n",
    "Time series analysis can be applied to real-valued, continuous data, discrete numeric data, or discrete symbolic data.\n",
    "[https://en.wikipedia.org/wiki/Time_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statsmodel\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import math\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize']  =  10, 6\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series = daily[['Date', 'Confirmed']]\n",
    "df_time_series = df_time_series.set_index('Date')\n",
    "df_time_series.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Analysis on total deceased cases\n",
    "\n",
    "Performing seasonal decomposition on \"total deceased\" column with model as \"additive\", store it in dataframe named decomposed_dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additive Decomposition\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "\n",
    "def generate():\n",
    "    decomposed_dataset = seasonal_decompose(df_time_series, model='additive', freq=1)\n",
    "    figure  =  decomposed_dataset.plot()\n",
    "    plt.show()\n",
    "    return decomposed_dataset\n",
    "\n",
    "decomposed_dataset = generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Analysing the stationarity of Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Define the p, d and q parameters to take any value between 0 and 2\n",
    "p = d = q = range(0, 3)\n",
    "\n",
    "# Generate all different combinations of p, q and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Generate all different combinations of seasonal p, q and q triplets\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 4) for x in list(itertools.product(p, d, q))]\n",
    "\n",
    "print('Examples of parameter combinations for Seasonal ARIMAX...')\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(df_time_series.totalconfirmed,\n",
    "                                            order=param,\n",
    "                                            seasonal_order=param_seasonal,\n",
    "                                            enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False)\n",
    "\n",
    "            results = mod.fit()\n",
    "            print('SARIMAX{}x{}4 - AIC:{}'.format(param, param_seasonal, results.aic))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "# do your work here\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting an SARIMAX Time Series Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with-out any Transpormation\n",
    "mod = sm.tsa.statespace.SARIMAX(df_time_series,\n",
    "                                order=(2, 1, 2),\n",
    "                                seasonal_order=(0, 2, 2, 4),\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "\n",
    "results = mod.fit(maxiter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_diagnostics(figsize=(18, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAXResults\n",
    "\n",
    "# save model\n",
    "results.save('model.pkl')\n",
    "# load model\n",
    "loaded = SARIMAXResults.load('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = loaded.get_prediction(start=pd.to_datetime('2020-01-13'), dynamic=False)\n",
    "pred_ci = pred.conf_int()\n",
    "ax = df_time_series['2020':].plot(label='observed')\n",
    "pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7, figsize=(14, 4))\n",
    "ax.fill_between(pred_ci.index,\n",
    "                pred_ci.iloc[:, 0],\n",
    "                pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Total +Ve Confirmed Case')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful information\n",
    "\n",
    "### Mexican Map with the Confirm, Recover and Deceased people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mexMap = folium.Map(location=[19,-102], tiles=\"cartodbpositron\", zoom_start=4)\n",
    "\n",
    "for lat, lon, value1,value2,value3, name in zip(newData['Latitude'], newData['Longitude'], newData['Confirmed'],newData['Recovered'],newData['Deceased'], newData['ENTIDAD_FEDERATIVA_RES']):\n",
    "    folium.CircleMarker([lat, lon],\n",
    "                        radius= (int((np.log(value1+1.00001))))*4,\n",
    "                        popup = ('<strong>States</strong>: ' + str(name).capitalize() + '<br>'\n",
    "                                '<strong>Confirmed</strong>: ' + str(value1) + '<br>'),\n",
    "                        color='#ff6600',\n",
    "                        \n",
    "                        fill_color='#ff8533',\n",
    "                        fill_opacity=0.4 ).add_to(mexMap)\n",
    "    \n",
    "    folium.CircleMarker([lat, lon],\n",
    "                        radius= (int((np.log(value2+1.00001))))*3,\n",
    "                        popup = ('<strong>States</strong>: ' + str(name).capitalize() + '<br>'\n",
    "                                '<strong>Recovered</strong>: ' + str(value2) + '<br>'),\n",
    "                        color='#008000',\n",
    "                        \n",
    "                        fill_color='#008000',\n",
    "                        fill_opacity=0.4 ).add_to(mexMap)\n",
    "    \n",
    "    folium.CircleMarker([lat, lon],\n",
    "                        radius= (int((np.log(value3+1.00001))))*2,\n",
    "                        popup = ('<strong>States</strong>: ' + str(name).capitalize() + '<br>'\n",
    "                                 '<strong>Deaths</strong>: ' + str(value3) + '<br>'),\n",
    "                        color='#0000A0',\n",
    "                        \n",
    "                        fill_color='#0000A0',\n",
    "                        fill_opacity=0.4 ).add_to(mexMap)\n",
    "mexMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ten confirmed and affected states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_topn_states(col, color=None, n=10):\n",
    "    df = newData.sort_values(col, ascending=False).head(n)\n",
    "    fig = px.bar(df, x=col, y='ENTIDAD_FEDERATIVA_RES', text=col, color='ENTIDAD_FEDERATIVA_RES', \n",
    "                 orientation='h', color_discrete_sequence=[color]\n",
    "                 )\n",
    "    fig.update_layout(title=col, xaxis_title=\"\", yaxis_title=\"\", \n",
    "                      yaxis_categoryorder = 'total ascending',\n",
    "                      showlegend=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topn_states('Confirmed', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ten states with more deceased people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topn_states('Deceased',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way to display the confirmed cases along the Mexican territory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = newData.groupby(['ENTIDAD_FEDERATIVA_RES'])['Confirmed'].sum().reset_index()\n",
    "temp.head()\n",
    "fig = px.treemap(temp, path=[\"ENTIDAD_FEDERATIVA_RES\"], values=\"Confirmed\", \n",
    "                 height=700, title='Number of Confirmed Cases', \n",
    "                 color_discrete_sequence = px.colors.qualitative.Vivid)\n",
    "fig.data[0].textinfo = 'label+text+value'\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical comparison between confirmed and deceased people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = daily[['Date','Confirmed','Dead']]\n",
    "temp = temp.melt(id_vars='Date', value_vars=['Confirmed', 'Dead'])\n",
    "temp.head()\n",
    "fig_c = px.line(temp, x=\"Date\", y=\"value\", color='variable', line_dash='variable', \n",
    "                color_discrete_sequence=[rec, dth])\n",
    "fig_c.update_layout(title='Confirmed vs Deceased cases', \n",
    "                  xaxis_title='', yaxis_title='')\n",
    "fig_c.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphic distribution by age and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_missing_vals():\n",
    "    print('Total no. of values : ', '{0:,.0f}'.format(data.shape[0]), \n",
    "          '\\nNo. of missing values :', '{0:,.0f}'.format(data.shape[0]-temp.shape[0]), \n",
    "          '\\nNo. of available values :', '{0:,.0f}'.format(data.shape[0]-(data.shape[0]-temp.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['EDAD_CLASS'] = pd.Categorical(data['EDAD_CLASS'],categories=['Baby','Child','Teenage','Young Adult','Adult','Senior Adult'])\n",
    "data = data.sort_values(by=['EDAD_CLASS'])\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2, column_widths=[0.8, 0.2],\n",
    "    subplot_titles = ['Gender vs Age', ''],\n",
    "    specs=[[{\"type\": \"histogram\"}, {\"type\": \"pie\"}]]\n",
    ")\n",
    "temp = data[['EDAD_CLASS', 'SEXO_DESC']].dropna()\n",
    "print_missing_vals()\n",
    "gen_grp = temp.groupby('SEXO_DESC').count()\n",
    "fig.add_trace(go.Histogram(x=temp[temp['SEXO_DESC']=='MUJER']['EDAD_CLASS'], nbinsx=50, name='Female', marker_color='#FF69B4'), 1, 1)\n",
    "fig.add_trace(go.Histogram(x=temp[temp['SEXO_DESC']=='HOMBRE']['EDAD_CLASS'], nbinsx=50, name='Male', marker_color='#000080'), 1, 1)\n",
    "\n",
    "fig.add_trace(go.Pie(values=gen_grp.values.reshape(-1).tolist(), labels=['Female', 'Male'], marker_colors = ['#FF69B4', '#000080']),1, 2)\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_layout(barmode='stack')\n",
    "fig.data[2].textinfo = 'label+text+value+percent'\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('rm -r ../Files/mex_covid_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
